{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Maze:\n",
    "    def __init__(self, maze, start_position, goal_position):\n",
    "        self.maze = maze\n",
    "        self.maze_height, self.maze_width = maze.shape #get height and width of the maze\n",
    "        self.start_position = start_position#set start position as tuple\n",
    "        self.goal_position = goal_position\n",
    "\n",
    "    def show_maze(self):\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(self.maze, cmap='gray')\n",
    "        #add start and end position 'S' & 'G'\n",
    "        plt.text(self.start_position[1], self.start_position[0], 'S', ha='center', va='center', color='red', fontsize=20)\n",
    "        plt.text(self.goal_position[1], self.goal_position[0], 'G', ha='center', va='center', color='green', fontsize=20)\n",
    "        plt.xticks([]), plt.yticks([])\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actions: Up, Down, Left, Right\n",
    "actions = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAGVCAYAAADZmQcFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAANU0lEQVR4nO3dX4xedZ3H8e/TzJaWMtMNpXRbOwIqTbDRBjWY2iC4u0iy0WpQ4oUbCSFcemO9EE2IJsakN95sTPZCXZcEjV7oSv2Df8uGRQz4h2JQutSEXeykpcXamf7DbefsxZNpFfp0nmk/nXOm83rd8MzMmZlvzgzn3d9zznmm1zRNUwBwgZa0PQAAlwZBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIkaG2Wh6eromJiZqdHS0er3exZ4JgA5pmqampqZq3bp1tWTJ4HXIUEGZmJio8fHx2HAALDwvvPBCrV+/fuDHh3rKa3R0NDYQAAvTbC0YKiie5gJgthY4KQ9AhKAAECEoAEQICgARggJAhKAAECEoAEQICgARggJAhKAAECEoAEQICgARggJAhKAAECEoAEQICgARggJAhKAAECEoAEQICgARggJAhKAAECEoAEQICgARggJAhKAAECEoAEQICgARggJAhKAAECEoAEQICgARggJAhKAAECEoAESMtD3AhWqapu0RBur1em2PcFZd3mewmHX1mDEsKxQAIgQFgAhBASBCUACIEBQAIgQFgIgFf9nwBTt6tOrBB6u+/e2qXbuqDh6sGhmpuvrqqjVrqjZtqrr11qpbbqlau7btaQE6q9cMcVPC5ORkrVy5cj7mmbMLuqfiiSeqPvShquefn33bNWuq9u2b05fv6jXl7kOBburqMWPG4cOHa2xsbODHF+8KZc+eqttuq5qc7L+9dWvVBz9YtWFD1dKl/ZXKrl1VP/pR1c6d7c4KsAAs3qB86lNnYvLlL1fdffert7nttqqPf7zqwIGqb3xjfucDWGAW51Nep05VjY1VHTtW9ba3VT35ZH6w6u7y1VNe0E1dPWbMmO0pr8V5ldeBA/2YVFW94Q3tzgJwiVicQVm69Mzj3/2uvTkALiGLMyhXXll1zTX9x7t2VW3fXjU93e5MAAvc4gxKVdVHP3rm8Sc+UfW61/Xf99WvVv3+9+3NBbBALc6T8lX9Fcm99/av8DqbNWv6NzR++MNV73lP1XmcLOvqCTYn5aGbunrMmOGk/CBLllR96UtV3/9+//LgJa/YFfv3V3396/37U266yaoFYBaLd4XySocOVT32WNUvflH1y19WPfpo1eHDZz6+dm3//XN4+ZWu/mvDCgW6qavHjBmzrVAEZZCXX+6fT9m2rR+bqqp77qn64heH/hJd/eUQFOimrh4zZnjK63xddln/7vmvfe3M+775TVeDAQwgKLO5/faq8fH+40OHql56qd15ADpKUIaxbt2Zx688eQ9AVQnK7I4dq/rtb/uPx8b6N0UC8CqLMyhHjlS9/e1V3/nOuc+JTE/3b3acmuq/vXXred2PArAYLM6rvI4cqRod7T9+zWuq3v/+qs2b+y/HMjpa9ac/Vf361/2bHn/zm/52K1dWPfVU1bXXDv1tunrFhqu8oJu6esyY4bLhszlxouq664b/C4zXX9+/2uutb53Tt+nqL4egQDd19Zgxw19sPJtly6r27q36+c+rfvzj/n937+7fHX/iRNWKFf0T8Zs2Vb3vfVUf+MBfv0IxAK+yOFco86Sr/9ro8j6Dxayrx4wZbmwEYF4ICgARggJAhKAAECEoAEQICgARggJAhKAAECEoAEQICgARi/O1vOaJlziZu66+9ISf5dx19WdZ5ed5sVihABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAx0vYAF6rX67U9woLTNE3bIxDk/wG6wgoFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBipO0BLlTTNG2PQJCf59zZZ3SFFQoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAESNtD3Ap6/V6bY9wVk3TtD3CQF3dZ8DsrFAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACJG2h4AFoKmadoegUWg1+u1PcIFsUIBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIGKk7QGYf71er+0RCPLznLumadoe4ZJkhQJAhKAAECEoAEQICgARggJAhKAAECEoAEQICgARggJAhKAAECEoAEQICgARggJAhKAAECEoAEQICgARggJAhKAAECEoAEQICgARggJAhKAAECEoAEQICgARggJAhKAAECEoAEQICgARggJAhKAAECEoAEQICgARggJAhKAAECEoAEQICgARggJAhKAAEDHS9gCXsqZp2h6BRaCrv2e9Xq/tEZhnVigARAgKABGCAkCEoAAQISgARLjKC2AOppvpemj3Q/WDPT+on/3hZ7XvyL46dPxQLRtZVlddflW9ac2bavP6zXXHDXfUhlUb2h53XvWaIa45nJycrJUrV87HPHPW1UsmYbHr8mXD53vc+N5z36ttP9xWzx58dqjtb7nmlvrcP3yu3jH+jqG27/I+q6o6fPhwjY2NDfy4oAAXRZcPjudz3Nj+X9vrvp/cV031P3fL+JZ674b31o1rb6xVy1fViZMnav/R/fXY/z5W333uu7X7pd1VVXX762+vh//54aG+R5f3WZWgAC3p8sFxrseNB3Y9UHf9x11VVXXV5VfVg3c8WO9+/bvP+fV3/PeOuu8n99X42Lig/CVBAeaqywfHuRw39k7urev/5fo6fvJ4rfibFfXkvU/WDatvGOpzT5w8UTt276g7N9451PZd3mdVswfFVV4A5/D5xz9fx08er6qqz/79Z4eOSVXVspFlQ8fkUiAoAAM0TVMPPP1AVVVdsfSKuufGe1qeqNsEBWCAZw48UwePHayqqptfe3ONXjba8kTdJigAAzy9/+nTj9+y9i0tTrIwuLERYICZ1UlV1erLV59z22defOb0JcWvdN3fXlcrlq6IztZFggIwwNTLU6cfX7H0inNuu+lfN9Wp5tRZP7bzrp1167W3JkfrJE95AQzwl+dMjv7f0RYnWRisUAAGWLV81enHB44eOOe2J+8/+Vdvf/qRT9dn/vMzF2WurrJCARhg099tOv34V/t+1eIkC4OgAAywcfXG06uUR//n0Tr6Z097nYugAAzQ6/XqI5s+UlVVU3+eqq889ZV2B+o4QQE4h49t/lgtH1leVVWf/Okna88f97Q8UXcJCsA5rB9bX1/4py9UVdXky5N187/dXI88/8isn3fo+KGLPFn3uMoLYBZ333h37Z3aW/fvvL/2HdlX7/r3d9U7r3lnbd2wtd685s216vJV1TRNvXj0xdq1f1d969lv1RN7nzj9+TMrnEudl68HLoouvxT7+R43duzeUdt+uK2e++NzQ22/ZXxLbf/H7bXltVuG2r7L+6zK30MBWtLlg+OFHDdOTZ+qh3Y/VA/vebge/8Pj/b8pf+JQLR9ZXlcuv7I2Xr2xblp3U9258c564+o3zulrd3mfVQkK0JIuHxy7etzo8j6r8ge2AJgnggJAhKAAECEoAEQICgARggJAhKAAECEoAEQICgARggJAxIJ/teGuv1QB0D2OGxeHFQoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEUMFpWmaiz0HAB03WwuGCsrU1FRkGAAWrtla0GuGWH5MT0/XxMREjY6OVq/Xiw0HQPc1TVNTU1O1bt26WrJk8DpkqKAAwGyclAcgQlAAiBAUACIEBYAIQQEgQlAAiBAUACL+H53DwksZYFx6AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create any maze \n",
    "maze_layout = np.array([\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 1, 1, 1, 1, 1, 1, 0],\n",
    "    [0, 1, 1, 1, 0, 1, 1, 0, 1, 0],\n",
    "    [0, 0, 0, 1, 0, 1, 0, 0, 1, 0],\n",
    "    [0, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "    [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 1, 0, 1, 1, 1, 1, 0],\n",
    "    [0, 1, 0, 0, 0, 1, 0, 0, 1, 0],\n",
    "    [0, 1, 1, 1, 1, 1, 1, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "])\n",
    "\n",
    "# Create an instance of the maze and set the starting and ending positions\n",
    "maze = Maze(maze_layout, (1, 1), (8, 8))\n",
    "maze.show_maze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent:\n",
    "    def __init__(self, maze, learning_rate=0.1, discount_factor=0.9, exploration_start=1.0, exploration_end=0.01, num_episodes=100):\n",
    "        self.q_table = np.zeros((maze.maze_height, maze.maze_width, 4))\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.exploration_start = exploration_start\n",
    "        self.exploration_end = exploration_end\n",
    "        self.num_episodes = num_episodes\n",
    "\n",
    "    def get_exploration_rate(self, current_episode):\n",
    "        return self.exploration_start * (self.exploration_end / self.exploration_start) ** (current_episode / self.num_episodes)\n",
    "\n",
    "    def get_action(self, state, current_episode):\n",
    "        exploration_rate = self.get_exploration_rate(current_episode)\n",
    "        if np.random.rand() < exploration_rate:\n",
    "            return np.random.randint(4)\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state])\n",
    "\n",
    "    def update_q_table(self, state, action, next_state, reward):\n",
    "        best_next_action = np.argmax(self.q_table[next_state])\n",
    "        current_q_value = self.q_table[state][action]\n",
    "        new_q_value = current_q_value + self.learning_rate * (reward + self.discount_factor * self.q_table[next_state][best_next_action] - current_q_value)\n",
    "        self.q_table[state][action] = new_q_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reward system\n",
    "goal_reward = 100\n",
    "wall_penalty = -10\n",
    "step_penalty = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finish_episode(agent, maze, current_episode, train=True):\n",
    "    current_state = maze.start_position\n",
    "    is_done = False\n",
    "    episode_reward = 0\n",
    "    episode_step = 0\n",
    "    path = [current_state]\n",
    "\n",
    "    while not is_done:\n",
    "        action = agent.get_action(current_state, current_episode)\n",
    "        next_state = (current_state[0] + actions[action][0], current_state[1] + actions[action][1])\n",
    "\n",
    "        if (next_state[0] < 0 or next_state[0] >= maze.maze_height or \n",
    "            next_state[1] < 0 or next_state[1] >= maze.maze_width or \n",
    "            maze.maze[next_state[0]][next_state[1]] == 1):\n",
    "            reward = wall_penalty\n",
    "            next_state = current_state\n",
    "        elif next_state == maze.goal_position:\n",
    "            path.append(next_state)\n",
    "            reward = goal_reward\n",
    "            is_done = True\n",
    "        else:\n",
    "            path.append(next_state)\n",
    "            reward = step_penalty\n",
    "\n",
    "        episode_reward += reward\n",
    "        episode_step += 1\n",
    "\n",
    "        if train:\n",
    "            agent.update_q_table(current_state, action, next_state, reward)\n",
    "\n",
    "        current_state = next_state\n",
    "\n",
    "    return episode_reward, episode_step, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(agent, maze, num_episodes=1):\n",
    "    episode_reward, episode_step, path = finish_episode(agent, maze, num_episodes, train=False)\n",
    "\n",
    "    print(\"Learned Path:\")\n",
    "    for row, col in path:\n",
    "        print(f\"({row}, {col}) -> \", end='')\n",
    "    print(\"Goal!\")\n",
    "\n",
    "    print(f\"Number of steps: {episode_step}\")\n",
    "    print(f\"Total reward: {episode_reward}\")\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(maze.maze, cmap='gray')\n",
    "    plt.text(maze.start_position[1], maze.start_position[0], 'S', ha='center', va='center', color='red', fontsize=20)\n",
    "    plt.text(maze.goal_position[1], maze.goal_position[0], 'G', ha='center', va='center', color='green', fontsize=20)\n",
    "\n",
    "    for position in path:\n",
    "        plt.text(position[1], position[0], \"#\", ha='center', va='center', color='blue', fontsize=20)\n",
    "\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.grid(color='black', linewidth=2)\n",
    "    plt.show()\n",
    "\n",
    "    return episode_step, episode_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(agent, maze, num_episodes=100):\n",
    "    episode_rewards = []\n",
    "    episode_steps = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        episode_reward, episode_step, _ = finish_episode(agent, maze, episode, train=True)\n",
    "        episode_rewards.append(episode_reward)\n",
    "        episode_steps.append(episode_step)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(episode_rewards)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Cumulative Reward')\n",
    "    plt.title('Reward per Episode')\n",
    "\n",
    "    average_reward = sum(episode_rewards) / len(episode_rewards)\n",
    "    print(f\"The average reward is: {average_reward:.2f}\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(episode_steps)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Steps Taken')\n",
    "    plt.ylim(0, max(episode_steps))\n",
    "    plt.title('Steps per Episode')\n",
    "\n",
    "    average_steps = sum(episode_steps) / len(episode_steps)\n",
    "    print(f\"The average number of steps is: {average_steps:.2f}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = QLearningAgent(maze)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Training the agent\n",
    "train_agent(agent, maze, num_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the agent after training\n",
    "test_agent(agent, maze, num_episodes=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
